{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "- decide on brain state data structure (maybe reformat it inside of the sim?)\n",
    "- add text describing brain state/mental state/mental representation/functionalism/etc..\n",
    "- clean up the NN models / function calls on the networks to make them more intuitive for explaination\n",
    "- clean up trainedmentalagent construction / class code\n",
    "- nicely package training scripts for behavior and mental state classification (implement train/test for mental state clf)\n",
    "- fix all the pytorch cuda/cpu drama\n",
    "- set random seeds for all sims\n",
    "- add explainations/text throughout notebook\n",
    "- general notebook cleaning\n",
    "- make notebook work on colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Many theories of mind rest on how brain states and mental states are defined and their relationship.\n",
    "- I want to try to (faithfully to most theories of mind) define brain states, mental states, and their relationships in code.\n",
    "- We can then use these definitions to build descriptions of theories of mind in code.\n",
    "- I am not presenting a cognitive architecture or even accepting computational theory of mind. \n",
    "- *I'm simply trying to use code to more clearly talk about what we mean and have more concrete disagreements.*\n",
    "- Like a thought experiment, but with a simulate buttom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "import world\n",
    "from dqn_agent import DQNAgent\n",
    "from visualization_utils import *\n",
    "from model import MLP\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feel for the simulation world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"480\" height=\"360\" controls>\n",
       "  <source src=\"../openai_lunarlander_video.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"480\" height=\"360\" controls>\n",
    "  <source src=\"../openai_lunarlander_video.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feel for how agents are described"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An agent who takes no actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoNothingAgent(object):\n",
    "    \n",
    "    name = 'do_nothing_agent'\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def act(self, world_observation):\n",
    "        return 0\n",
    "\n",
    "    \n",
    "agent = DoNothingAgent()\n",
    "\n",
    "_ = world.run_episode(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An agent who takes random actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(object):\n",
    "    \n",
    "    name = 'random_agent'\n",
    "\n",
    "    def __init__(self, num_actions=4):\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "    def act(self, world_observation):\n",
    "        return random.randint(0, self.num_actions-1)\n",
    "\n",
    "    \n",
    "agent = RandomAgent()\n",
    "\n",
    "_ = world.run_episode(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An agent that was trained (using reinforcement learning) to perform well in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dqn_agent import BehaviorNetwork\n",
    "\n",
    "class Brain(object):\n",
    "    \n",
    "    def __init__(self, use_pretrained=True):\n",
    "        if use_pretrained:\n",
    "            self.behavior_network = DQNAgent()\n",
    "            self.behavior_network.qnetwork_local.load_state_dict(torch.load('../checkpoint0.pth', map_location='cpu'))\n",
    "            self.behavior_network.qnetwork_local.fc1.cpu()\n",
    "            self.behavior_network.qnetwork_local.fc2.cpu()\n",
    "            self.behavior_network.qnetwork_local.fc3.cpu()\n",
    "        else:\n",
    "            self.behavior_network.train('LunarLander-v2')\n",
    "            \n",
    "    def brain_state(self, world_observation):\n",
    "        brain_state = []\n",
    "        network = self.behavior_network.qnetwork_local\n",
    "        x = world_observation\n",
    "        activations = x\n",
    "        for i, subnet in enumerate(network.children()):\n",
    "            try:\n",
    "                subbrain_state = subnet.weight.detach().clone().cpu().numpy() * activations.detach().clone().cpu().numpy()\n",
    "            except AttributeError:\n",
    "                subbrain_state = subnet.weight.detach().clone().cpu().numpy() * activations\n",
    "            brain_state.append(subbrain_state)\n",
    "            activations = F.relu(subnet.cpu().float()(torch.tensor(activations).float()))\n",
    "        return brain_state\n",
    "\n",
    "    def suggest_action(self, state):\n",
    "        return self.behavior_network.act(state)\n",
    "\n",
    "\n",
    "class TrainedBehaviorAgent(object):\n",
    "    \n",
    "    name = 'trained_behavior_agent'\n",
    "\n",
    "    def __init__(self):\n",
    "        self.brain = Brain(use_pretrained=True)\n",
    "\n",
    "    def act(self, world_observation):\n",
    "        return self.brain.suggest_action(world_observation)\n",
    "    \n",
    "    def image_brain_state(self, world_observation):\n",
    "        return self.brain.brain_state(world_observation)\n",
    "        \n",
    "\n",
    "    \n",
    "agent = TrainedBehaviorAgent()\n",
    "\n",
    "episode_history = world.run_episode(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent.dqn_agent.qnetwork_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.dqn_agent.qnetwork_local.fc2.weight.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_weights(agent.dqn_agent.qnetwork_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_index = 50\n",
    "visualize_state(episode_history['world_image'][episode_index])\n",
    "visualize_activations(agent.dqn_agent.qnetwork_local, episode_history['world_observation'][episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_index = -50\n",
    "visualize_state(episode_history['world_image'][episode_index])\n",
    "visualize_activations(agent.dqn_agent.qnetwork_local, episode_history['world_observation'][episode_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An agent that was trained (using reinforcement learning) to perform well in the environment and was trained (using supervised learning) to recognize its own mental states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mental_state_labels = [\n",
    "    [\"I believe I'm falling to fast\", lambda state: state[3] < -0.2],\n",
    "    [\"I desire to land\", lambda state: state[-2] != 1 and state[-1] != 1],\n",
    "    [\"I'm afraid to tip over\", lambda state: np.abs(state[5]) > 0.2],\n",
    "    [\"I desire to go left\", lambda state: state[0] > 0.2],\n",
    "    [\"I desire to go right\", lambda state: state[0] < -0.2]\n",
    "]\n",
    "\n",
    "class TrainedMentalAgent(TrainedBehaviorAgent):\n",
    "    \n",
    "    name = 'trained_mental_agent'\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TrainedMentalAgent, self).__init__()\n",
    "        self.mental_state_classifier = MLP(num_neurons=1408, \n",
    "                                           num_mental_states=len(mental_state_labels), \n",
    "                                           fc_units=32)\n",
    "        self.mental_state_classifier.load_state_dict(torch.load('../mental_classifer.pth'))\n",
    "        self.mental_state_classifier.cpu()\n",
    "        self.mental_state_labels = mental_state_labels\n",
    "        \n",
    "    def report_mental_state(self, state):\n",
    "        brain_state = self.brain.brain_state(state)\n",
    "        brain_state = np.concatenate([array.flatten() for array in brain_state])\n",
    "        mental_state = F.sigmoid(self.mental_state_classifier(torch.tensor(brain_state).float())).detach().clone().cpu().numpy()\n",
    "        return [agent.mental_state_labels[i][0] for i, m in enumerate(mental_state) if m > 0.5]\n",
    "\n",
    "\n",
    "agent = TrainedMentalAgent()\n",
    "\n",
    "episode_history = world.run_episode(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animate_episode_history(episode_history, agent, steps_size=25, pause=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common theories of mind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behaviorism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from OpenAI's heuristic controller for lunar lander \n",
    "\n",
    "class BehaviorismAgent(object):\n",
    "    \n",
    "    name = 'behaviorism_agent'\n",
    "\n",
    "    def __init__(self, num_actions=4):\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "    def act(self, world_observation):\n",
    "        s = world_observation\n",
    "        angle_todo = (s[0]*0.5 + s[2]*1.0 - s[4])*0.5 - (s[5])*1.0\n",
    "        hover_todo = (0.55*np.abs(s[0]) - s[1])*0.5 - (s[3])*0.5\n",
    "        if s[6] or s[7]:\n",
    "            angle_todo, hover_todo = 0, -(s[3])*0.5 \n",
    "        a = 0\n",
    "        if hover_todo > np.abs(angle_todo) and hover_todo > 0.05:\n",
    "            a = 2\n",
    "        elif angle_todo < -0.05: \n",
    "            a = 3\n",
    "        elif angle_todo > +0.05: \n",
    "            a = 1\n",
    "        return a\n",
    "\n",
    "    \n",
    "agent = BehaviorismAgent()\n",
    "\n",
    "episode_history = world.run_episode(agent)\n",
    "\n",
    "episode_history['brain_state'] = None\n",
    "episode_history['reported_mental_state'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animate_episode_history(episode_history, agent, steps_size=50, pause=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token-token Identity Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = TrainedMentalAgent()\n",
    "\n",
    "episode_history = world.run_episode(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.asarray([0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], dtype=np.float32)\n",
    "visualize_activations(agent.dqn_agent.qnetwork_local, state)\n",
    "print('\\n'.join(agent.report_mental_state(state)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.asarray([0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], dtype=np.float32)\n",
    "visualize_activations(agent.dqn_agent.qnetwork_local, state)\n",
    "print('\\n'.join(agent.report_mental_state(state)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.asarray([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], dtype=np.float32)\n",
    "visualize_activations(agent.dqn_agent.qnetwork_local, state)\n",
    "print('\\n'.join(agent.report_mental_state(state)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.asarray([1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], dtype=np.float32)\n",
    "visualize_activations(agent.dqn_agent.qnetwork_local, state)\n",
    "print('\\n'.join(agent.report_mental_state(state)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionalism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionalismAgent(object):\n",
    "    \n",
    "    name = 'functionalism_agent'\n",
    "\n",
    "    def __init__(self, num_actions=4):\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "    def act(self, world_observation):\n",
    "        \n",
    "        if self.falling_too_fast_belief_mental_state(world_observation):\n",
    "            a = 2\n",
    "        elif self.fear_of_tipping_to_the_left(world_observation):\n",
    "            a = 3\n",
    "        elif self.fear_of_tipping_to_the_right(world_observation):\n",
    "            a = 1\n",
    "        elif self.desire_go_left_mental_state(world_observation):\n",
    "            a = 1\n",
    "        elif self.desire_go_right_mental_state(world_observation):\n",
    "            a = 3\n",
    "        elif self.desire_to_land_mental_state(world_observation):\n",
    "            a = 0\n",
    "        else:\n",
    "            a = 0\n",
    "        return a\n",
    "    \n",
    "    def fear_of_tipping_to_the_left(self, world_observation):\n",
    "        s = world_observation\n",
    "        angle_todo = (s[0]*0.5 + s[2]*1.0 - s[4])*0.5 - (s[5])*1.0\n",
    "        hover_todo = (0.55*np.abs(s[0]) - s[1])*0.5 - (s[3])*0.5\n",
    "        return (not (hover_todo > np.abs(angle_todo) and hover_todo > 0.05) \n",
    "                and angle_todo < -0.05)\n",
    "    \n",
    "    def fear_of_tipping_to_the_right(self, world_observation):\n",
    "        s = world_observation\n",
    "        angle_todo = (s[0]*0.5 + s[2]*1.0 - s[4])*0.5 - (s[5])*1.0\n",
    "        hover_todo = (0.55*np.abs(s[0]) - s[1])*0.5 - (s[3])*0.5\n",
    "        return (not (hover_todo > np.abs(angle_todo) and hover_todo > 0.05) \n",
    "                and angle_todo > +0.05)\n",
    "    \n",
    "    def falling_too_fast_belief_mental_state(self, world_observation):\n",
    "        return world_observation[3] < -0.2\n",
    "    \n",
    "    def desire_to_land_mental_state(self, world_observation):\n",
    "        return (world_observation[-2] != 1 and world_observation[-1] != 1)\n",
    "    \n",
    "    def desire_go_left_mental_state(self, world_observation):\n",
    "        return world_observation[0] > 0.1\n",
    "    \n",
    "    def desire_go_right_mental_state(self, world_observation):\n",
    "        return world_observation[0] < -0.1\n",
    "        \n",
    "\n",
    "    \n",
    "agent = FunctionalismAgent()\n",
    "\n",
    "episode_history = world.run_episode(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open implementation questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Should the mental classificaiton network be part of the brain state? How does this answer depend on the chosen theory of mind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = TrainedMentalAgent()\n",
    "\n",
    "episode_history = world.run_episode(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_weights(agent.dqn_agent.qnetwork_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_weights(agent.mental_state_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_index = 50\n",
    "visualize_state(episode_history['world_image'][episode_index])\n",
    "visualize_activations(agent.dqn_agent.qnetwork_local, episode_history['world_observation'][episode_index])\n",
    "brain_state = np.concatenate([array.flatten() for array in episode_history['brain_state'][episode_index]])\n",
    "visualize_activations(agent.mental_state_classifier, brain_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The agent is epiphenomenal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dennett multiple drafts model of consciousness\n",
    "- Chalmers types of materialism\n",
    "- Non reductive materialism: Strawson's realistic monism, Davidson's anomalous monism\n",
    "- Weak emergence\n",
    "- Eliminative materialism\n",
    "- Searle's biological naturalism\n",
    "- Thoughts? Suggestions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
