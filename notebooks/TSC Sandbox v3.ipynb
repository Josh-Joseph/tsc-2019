{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import world\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def pretty_print(obj):\n",
    "    print(json.dumps(third_person_brain_state_ontology, indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd-person (objective) perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The world and an agent acting in the world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intuition for the world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[OpenAI's LunarLander-v2](https://gym.openai.com/envs/LunarLander-v2/)\n",
    "- The agent is a lunar lander attempting to softly land between the flags\n",
    "- Episode finishes if the lander crashes or comes to rest, receiving additional -100 or +100 points\n",
    "- Each leg ground contact is +10\n",
    "- Firing the engines is a small negative reward\n",
    "- Small positive reward for smoother flight\n",
    "- Fuel is infinite\n",
    "- Four discrete actions available: do nothing, fire left orientation engine, fire main engine, fire right orientation engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"480\" height=\"360\" controls>\n",
       "  <source src=\"../openai_lunarlander_video.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"480\" height=\"360\" controls>\n",
    "  <source src=\"../openai_lunarlander_video.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intuition for how agents are described"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The agent recieved -136 total reward\n"
     ]
    }
   ],
   "source": [
    "# An agent that does nothing\n",
    "\n",
    "class DoNothingAgent(object):\n",
    "\n",
    "    def act(self, observation):\n",
    "        return 0\n",
    "    \n",
    "agent = DoNothingAgent()\n",
    "episode_history = world.run_episode(agent)\n",
    "print(\"The agent recieved {} total reward\".format(int(round(sum(episode_history['reward'])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The agent recieved -133 total reward\n"
     ]
    }
   ],
   "source": [
    "# An agent that takes random actions\n",
    "\n",
    "class RandomAgent(object):\n",
    "\n",
    "    def act(self, observation):\n",
    "        return random.randint(0, 3)\n",
    "\n",
    "agent = RandomAgent()\n",
    "episode_history = world.run_episode(agent)\n",
    "print(\"The agent recieved {} total reward\".format(int(round(sum(episode_history['reward'])))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An agent who performs well in the world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from training import train_agent, load_pretrained_agent\n",
    "\n",
    "# Uncomment below if you wish to retrain the agent, otherwise it will use a pretrained, saved model\n",
    "# train_agent()\n",
    "\n",
    "agent = load_pretrained_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The agent recieved 272 total reward\n"
     ]
    }
   ],
   "source": [
    "episode_history = world.run_episode(agent)\n",
    "print(\"The agent recieved {} total reward\".format(int(round(sum(episode_history['reward'])))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A 3rd-person ontology over brain states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brain state in humans and animals: the full physical-chemical state of the brain and nervous system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brain_utils import third_person_brain_state_ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ontology(onto):\n",
    "    for type_name, python_type in onto.items():\n",
    "        print('{}: {}'.format(type_name, python_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_weights: <class 'list'>\n",
      "observation: <built-in function array>\n",
      "activations: <class 'list'>\n",
      "action: <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "print_ontology(third_person_brain_state_ontology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some brain state tokens of the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from world_utils import visualize_world\n",
    "from brain_utils import get_brain_state, visualize_weights, visualize_activations\n",
    "\n",
    "\n",
    "def visualize_third_person_brain_state_token(episode_index):\n",
    "\n",
    "    brain_state = get_brain_state(agent, episode_history['observation'][episode_index])\n",
    "\n",
    "    visualize_world(episode_history['world_image'][episode_index])\n",
    "    visualize_weights(brain_state)\n",
    "    visualize_activations(brain_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of backend CPU but got backend CUDA for argument #2 'mat2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f112b4ca371c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize_third_person_brain_state_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-d0e3397cca6b>\u001b[0m in \u001b[0;36mvisualize_third_person_brain_state_token\u001b[0;34m(episode_index)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvisualize_third_person_brain_state_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mbrain_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_brain_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'observation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepisode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mvisualize_world\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'world_image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepisode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/tsc-2019/brain_utils.py\u001b[0m in \u001b[0;36mget_brain_state\u001b[0;34m(agent, state_and_mental)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     activations.append(F.relu(networks[1](torch.cat([torch.tensor(activations[1]),\n\u001b[1;32m     36\u001b[0m                                                      torch.tensor(prev_mental)]))).detach().numpy())\n",
      "\u001b[0;32m~/.local/share/virtualenvs/tsc-2019-jd39_7cJ/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/tsc-2019-jd39_7cJ/lib/python3.5/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/tsc-2019-jd39_7cJ/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1408\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of backend CPU but got backend CUDA for argument #2 'mat2'"
     ]
    }
   ],
   "source": [
    "visualize_third_person_brain_state_token(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-dc6ba62d8af8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize_third_person_brain_state_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-d0e3397cca6b>\u001b[0m in \u001b[0;36mvisualize_third_person_brain_state_token\u001b[0;34m(episode_index)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvisualize_third_person_brain_state_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mbrain_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_brain_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'observation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepisode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mvisualize_world\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'world_image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepisode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "visualize_third_person_brain_state_token(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st-person (subjective) perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantically important areas for the agent (viewed from the 3rd-person perspective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high(observation):\n",
    "    return observation[1] > 0.2\n",
    "\n",
    "def low(observation):\n",
    "    return observation[1] <= 0.2\n",
    "\n",
    "def left(observation):\n",
    "    return observation[0] < -0.2\n",
    "\n",
    "def right(observation):\n",
    "    return observation[0] > 0.2\n",
    "\n",
    "def middle(observation):\n",
    "    return abs(observation[0]) < 0.2\n",
    "\n",
    "important_areas = [high, low, left, right, middle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_matching_area(observation):\n",
    "    for area in important_areas:\n",
    "        print('{}: {}'.format(area.__name__, area(episode_history['observation'][episode_index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high: True\n",
      "low: False\n",
      "left: False\n",
      "right: False\n",
      "middle: True\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "episode_index = 50\n",
    "\n",
    "visualize_world(episode_history['world_image'][episode_index])\n",
    "\n",
    "print_matching_area(episode_history['observation'][episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high: False\n",
      "low: True\n",
      "left: False\n",
      "right: False\n",
      "middle: True\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "episode_index = 155\n",
    "\n",
    "visualize_world(episode_history['world_image'][episode_index])\n",
    "\n",
    "print_matching_area(episode_history['observation'][episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ed4ac1713e45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepisode_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m225\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvisualize_world\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'world_image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepisode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint_matching_area\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'observation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepisode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "episode_index = 225\n",
    "\n",
    "visualize_world(episode_history['world_image'][episode_index])\n",
    "\n",
    "print_matching_area(episode_history['observation'][episode_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A 1st-person ontology over mental states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mental state in humans and animals: beliefs, desires, thoughts, perceptions, emotions, knowledge, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class area_set(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.areas = set()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(sorted(self.areas))\n",
    "    \n",
    "    def add_area(self, area):\n",
    "        self.areas.add(area)\n",
    "\n",
    "first_person_mental_state_ontology = {\n",
    "    'areas': area_set\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion of brain states to mental states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brain_state_to_mental_state(brain_state):\n",
    "    mental_state = {k: v() for k, v in first_person_mental_state_ontology.items()}\n",
    "    for i, area in enumerate(important_areas):\n",
    "        if brain_state['activations'][3][i] > 0.5:\n",
    "            mental_state['areas'].add_area(area.__name__)\n",
    "    return mental_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some mental state tokens of the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_mental_state(mental_state):\n",
    "    print(\"\"\"3rd-person report of the 1st-person view: \n",
    "    'I have the beliefs: {}'\"\"\".format(', '.join(mental_state['areas'].areas)))\n",
    "    \n",
    "def visualize_first_person_mental_state_token(episode_index):\n",
    "    \n",
    "    brain_state = get_brain_state(agent, episode_history['observation'][episode_index])\n",
    "\n",
    "    mental_state = brain_state_to_mental_state(brain_state)\n",
    "\n",
    "    report_mental_state(mental_state)\n",
    "    \n",
    "    visualize_world(episode_history['world_image'][episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of backend CPU but got backend CUDA for argument #2 'mat2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c02c406c7252>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepisode_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbrain_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_brain_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'observation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepisode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmental_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrain_state_to_mental_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrain_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/tsc-2019/brain_utils.py\u001b[0m in \u001b[0;36mget_brain_state\u001b[0;34m(agent, state_and_mental)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     activations.append(F.relu(networks[1](torch.cat([torch.tensor(activations[1]),\n\u001b[1;32m     36\u001b[0m                                                      torch.tensor(prev_mental)]))).detach().numpy())\n",
      "\u001b[0;32m~/.local/share/virtualenvs/tsc-2019-jd39_7cJ/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/tsc-2019-jd39_7cJ/lib/python3.5/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/tsc-2019-jd39_7cJ/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1408\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of backend CPU but got backend CUDA for argument #2 'mat2'"
     ]
    }
   ],
   "source": [
    "episode_index = 50\n",
    "\n",
    "brain_state = get_brain_state(agent, episode_history['observation'][episode_index])\n",
    "\n",
    "mental_state = brain_state_to_mental_state(brain_state)\n",
    "brain_state['activations'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_index = 155\n",
    "\n",
    "brain_state = get_brain_state(agent, episode_history['observation'][episode_index])\n",
    "\n",
    "mental_state = brain_state_to_mental_state(brain_state)\n",
    "brain_state['activations'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a9fa720a81c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepisode_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m225\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbrain_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_brain_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'observation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepisode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmental_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrain_state_to_mental_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrain_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "episode_index = 225\n",
    "\n",
    "brain_state = get_brain_state(agent, episode_history['observation'][episode_index])\n",
    "\n",
    "mental_state = brain_state_to_mental_state(brain_state)\n",
    "brain_state['activations'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of backend CPU but got backend CUDA for argument #2 'mat2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-c4c43b1ef5d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize_first_person_mental_state_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-d325895d131d>\u001b[0m in \u001b[0;36mvisualize_first_person_mental_state_token\u001b[0;34m(episode_index)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvisualize_first_person_mental_state_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mbrain_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_brain_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'observation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepisode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmental_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrain_state_to_mental_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrain_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/tsc-2019/brain_utils.py\u001b[0m in \u001b[0;36mget_brain_state\u001b[0;34m(agent, state_and_mental)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     activations.append(F.relu(networks[1](torch.cat([torch.tensor(activations[1]),\n\u001b[1;32m     36\u001b[0m                                                      torch.tensor(prev_mental)]))).detach().numpy())\n",
      "\u001b[0;32m~/.local/share/virtualenvs/tsc-2019-jd39_7cJ/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/tsc-2019-jd39_7cJ/lib/python3.5/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/tsc-2019-jd39_7cJ/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1408\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of backend CPU but got backend CUDA for argument #2 'mat2'"
     ]
    }
   ],
   "source": [
    "visualize_first_person_mental_state_token(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_first_person_mental_state_token(155)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_first_person_mental_state_token(225)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searle's view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mental state types are causally reducible to brain state types\n",
    "- Mental state types are ontologically irreducible to brain state types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal reducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phenomena of type A are causally reducible to phenomena of type B if and only if\n",
    "1. the behavior of A’s are entirely casually explained by the behavior of B’s\n",
    "1. A’s have no causal powers in addition to the powers of B’s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The agent's mental state behavior is causally explained by its brain states behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `brain_state_to_mental_state` is explicitly satisfying this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The agent's mental states have no causal powers in addition to the powers of its brain states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the neural network structure we can see all of the causal power is captured by the activations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ontological irreducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phenomena of type A are ontologically reducible to phenomena of type B if and only if A’s are nothing but B’s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The agent's mental states are not nothing but its brain states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_ontology(first_person_mental_state_ontology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_ontology(third_person_brain_state_ontology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the contentious pieces of this was the `brain_state_to_mental_state` function. A function that went from brain state types to mental state types. One way we can see even more clearly what is happening here is to note that this notebook is essentially the same argument as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_state = np.array([[2], [1]])\n",
    "brain_state_to_mental_state_matrix = np.matrix([[1, 0], [0, 1], [1, 1]])\n",
    "mental_state = brain_state_to_mental_state_matrix * brain_state\n",
    "\n",
    "print('Brain state: \\n{}\\n'.format(brain_state))\n",
    "print('Brain state to mental state \"function\": \\n{}\\n'.format(brain_state_to_mental_state_matrix))\n",
    "print('Mental state: \\n{}\\n'.format(mental_state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then noting that:\n",
    "- The \"mental state\" was created by a simple matrix multiplication with the \"brain state\" (hence, causally reducible)\n",
    "- The \"brain state\" is of type length-2-vector and the \"mental state\" of type length-3-vector where there is one ontology over length-2-vectors and another ontology over length-3-vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we'd be very curious to get thoughts on what this type conversion _means_ in the context of Searle's view (or even more broadly). Or is this confusion because we viewed (and implemented) `brain_state_to_mental_state` as a function and should have gone about that specifying that relationship another way?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "244px",
    "width": "518px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "329.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 482,
   "position": {
    "height": "40px",
    "left": "905px",
    "right": "20px",
    "top": "121px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
